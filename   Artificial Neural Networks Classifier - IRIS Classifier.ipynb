{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.iloc[:,0:4].values\n",
    "y=iris.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape) \n",
    "print (y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.datasets import load_digits \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_vars_stdscle = StandardScaler().fit_transform(X) \n",
    "x_train,x_test,y_train,y_test = train_test_split(x_vars_stdscle,y,train_size = 0.8,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV \n",
    "from sklearn.metrics import accuracy_score,classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "pipeline = Pipeline([('mlp',MLPClassifier(hidden_layer_sizes= (100,100,), \n",
    "                                          activation='relu',\n",
    "                                          solver='adam',\n",
    "                                          alpha=0.001,\n",
    "                                          max_iter=300 ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'mlp__alpha':(0.001,0.01,0.1,0.3,0.5,1.0), \n",
    "              'mlp__max_iter':(100,200,300)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   17.7s finished\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('mlp',\n",
       "                                        MLPClassifier(activation='relu',\n",
       "                                                      alpha=0.001,\n",
       "                                                      batch_size='auto',\n",
       "                                                      beta_1=0.9, beta_2=0.999,\n",
       "                                                      early_stopping=False,\n",
       "                                                      epsilon=1e-08,\n",
       "                                                      hidden_layer_sizes=(100,\n",
       "                                                                          100),\n",
       "                                                      learning_rate='constant',\n",
       "                                                      learning_rate_init=0.001,\n",
       "                                                      max_fun=15000,\n",
       "                                                      max_iter=300,\n",
       "                                                      momentum=0.9,\n",
       "                                                      n_iter_no_change=10,\n",
       "                                                      nesterovs_m...um=True,\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=None,\n",
       "                                                      shuffle=True,\n",
       "                                                      solver='adam', tol=0.0001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=False,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'mlp__alpha': (0.001, 0.01, 0.1, 0.3, 0.5, 1.0),\n",
       "                         'mlp__max_iter': (100, 200, 300)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_nn = GridSearchCV(pipeline,\n",
    "                              parameters,\n",
    "                              n_jobs=-1,\n",
    "                              cv=5,\n",
    "                              verbose=1, \n",
    "                              scoring='accuracy') \n",
    "grid_search_nn.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Neural Network Best Training score: 0.958\n",
      "\n",
      "Neural Network Best parameters set:\n",
      "\tmlp__alpha: 1.0\n",
      "\tmlp__max_iter: 300\n"
     ]
    }
   ],
   "source": [
    "print ('\\n\\nNeural Network Best Training score: %0.3f' % grid_search_nn.best_score_) \n",
    "print ('\\nNeural Network Best parameters set:') \n",
    "best_parameters = grid_search_nn.best_estimator_.get_params() \n",
    "for param_name in sorted(parameters.keys()): \n",
    "    print ('\\t%s: %r' % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Training accuracy: 0.9833\n",
      "\n",
      "Neural Network Complete report of Training data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        40\n",
      "  versicolor       0.98      0.98      0.98        41\n",
      "   virginica       0.97      0.97      0.97        39\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.98      0.98      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "\n",
      "\n",
      "Neural Network Grid Search- Train Confusion Matrix\n",
      "\n",
      " Predicted   setosa  versicolor  virginica\n",
      "Actuall                                  \n",
      "setosa          40           0          0\n",
      "versicolor       0          40          1\n",
      "virginica        0           1         38\n"
     ]
    }
   ],
   "source": [
    "predictions_train = grid_search_nn.predict(x_train) \n",
    "predictions_test = grid_search_nn.predict(x_test) \n",
    "print (\"\\nNeural Network Training accuracy:\",\n",
    "       round(accuracy_score(y_train, predictions_train),\n",
    "             4)) \n",
    "print (\"\\nNeural Network Complete report of Training data\\n\",\n",
    "       classification_report(y_train, predictions_train)) \n",
    "print (\"\\n\\nNeural Network Grid Search- Train Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_train, predictions_train,rownames = [\"Actuall\"],\n",
    "                   colnames = [\"Predicted\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Neural Network Testing accuracy: 1.0\n",
      "\n",
      "Neural Network Complete report of Testing data\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "\n",
      "Neural Network Grid Search- Test Confusion Matrix\n",
      "\n",
      " Predicted   setosa  versicolor  virginica\n",
      "Actuall                                  \n",
      "setosa          10           0          0\n",
      "versicolor       0           9          0\n",
      "virginica        0           0         11\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\\nNeural Network Testing accuracy:\",round(accuracy_score(y_test, predictions_test),4)) \n",
    "print (\"\\nNeural Network Complete report of Testing data\\n\",\n",
    "       classification_report( y_test, predictions_test)) \n",
    "print (\"\\n\\nNeural Network Grid Search- Test Confusion Matrix\\n\\n\",\n",
    "       pd.crosstab(y_test, predictions_test,rownames = [\"Actuall\"],colnames = [\"Predicted\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
